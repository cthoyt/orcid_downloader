{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc6ff47-b758-48e8-9753-847d34774a0c",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "This script makes some queries to PubMed and extracts author\n",
    "affiliation information for the purpose of writing a rule-based\n",
    "function that extracts top-level institution names.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "from gilda import Term\n",
    "from gilda.ner import annotate\n",
    "from gilda.process import normalize\n",
    "from indra.literature import pubmed_client\n",
    "from pyobo.gilda_utils import get_grounder\n",
    "\n",
    "with open(\"/Users/cthoyt/dev/rorio/countries.json\") as file:\n",
    "    ror_to_country_geoname = json.load(file)\n",
    "\n",
    "organization_grounder = get_grounder(\"ror\", skip_obsolete=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "754e8fd4-fb13-4733-b799-4d31863fbbd5",
   "metadata": {},
   "source": [
    "assert \"041nas322\" == organization_grounder.ground(\"University of Bonn\")[0].term.id\n",
    "assert \"00trw9c49\" == organization_grounder.ground(\"Fraunhofer SCAI\")[0].term.id\n",
    "# FIXME\n",
    "# assert \"00rqy9422\" == organization_grounder.ground(\"The University of Queensland\")[0].term.id"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5470137-44ab-46db-9970-8c6ef4af80e4",
   "metadata": {},
   "source": [
    "geonames_grounder = get_grounder(\"geonames\")\n",
    "\n",
    "extra_terms = [\n",
    "    Term(\n",
    "        normalize(\"United States of America\"),\n",
    "        \"United States of America\",\n",
    "        \"geonames\",\n",
    "        \"6252001\",\n",
    "        \"United States\",\n",
    "        \"synonym\",\n",
    "        \"geonames\",\n",
    "    ),\n",
    "    Term(normalize(\"USA\"), \"USA\", \"geonames\", \"6252001\", \"United States\", \"synonym\", \"geonames\"),\n",
    "    Term(normalize(\"UK\"), \"UK\", \"geonames\", \"2635167\", \"United Kingdom\", \"synonym\", \"geonames\"),\n",
    "    Term(normalize(\"PR China\"), \"PR China\", \"geonames\", \"1814991\", \"China\", \"synonym\", \"geonames\"),\n",
    "    Term(\n",
    "        normalize(\"People's Republic of China\"),\n",
    "        \"People's Republic of China\",\n",
    "        \"geonames\",\n",
    "        \"1814991\",\n",
    "        \"China\",\n",
    "        \"synonym\",\n",
    "        \"geonames\",\n",
    "    ),\n",
    "    Term(normalize(\"Sweeden\"), \"Sweeden\", \"geonames\", \"2661886\", \"Sweden\", \"synonym\", \"geonames\"),\n",
    "    Term(\n",
    "        normalize(\"Czech Republic\"),\n",
    "        \"Czech Republic\",\n",
    "        \"geonames\",\n",
    "        \"3077311\",\n",
    "        \"Czechia\",\n",
    "        \"synonym\",\n",
    "        \"geonames\",\n",
    "    ),\n",
    "    Term(normalize(\"Brasil\"), \"Brasil\", \"geonames\", \"3469034\", \"Brazil\", \"synonym\", \"geonames\"),\n",
    "    Term(normalize(\"Brasília\"), \"Brasília\", \"geonames\", \"3469034\", \"Brazil\", \"synonym\", \"geonames\"),\n",
    "    Term(\n",
    "        normalize(\"Republic of South Africa\"),\n",
    "        \"Republic of South Africa\",\n",
    "        \"geonames\",\n",
    "        \"953987\",\n",
    "        \"South Africa\",\n",
    "        \"synonym\",\n",
    "        \"geonames\",\n",
    "    ),\n",
    "    Term(\n",
    "        normalize(\"Republic of Korea\"),\n",
    "        \"Republic of Korea\",\n",
    "        \"geonames\",\n",
    "        \"1835841\",\n",
    "        \"South Korea\",\n",
    "        \"synonym\",\n",
    "        \"geonames\",\n",
    "    ),\n",
    "]\n",
    "for term in extra_terms:\n",
    "    geonames_grounder.entries.setdefault(term.norm_text, []).append(term)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47b085f9-6912-474a-88e4-140a3383f291",
   "metadata": {},
   "source": [
    "queries = [\n",
    "    '\"Steven B Bradfute\"',\n",
    "    '\"Charles Tapley Hoyt\"',\n",
    "    '\"Benjamin Gyori\"',\n",
    "]\n",
    "records = {}\n",
    "for query in queries:\n",
    "    pmids = pubmed_client.get_ids(query, use_text_word=False)\n",
    "    records.update(pubmed_client.get_metadata_for_ids(pmids, detailed_authors=True))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03c82d28-bff4-46d7-8d92-d3e466b5c3d1",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "counter = Counter()\n",
    "for record in records.values():\n",
    "    for author in record.get(\"authors\", []):\n",
    "        for affiliation in author.get(\"affiliations\", []):\n",
    "            name = affiliation[\"name\"]\n",
    "            name = (\n",
    "                name.replace(\"\\n\", \" \")\n",
    "                .replace(\"\\t\", \" \")\n",
    "                .replace(\" , \", \", \")\n",
    "                .replace(\"  \", \" \")\n",
    "                .strip(\".\")\n",
    "            )\n",
    "            if name[0].isdigit():\n",
    "                name = name[1:].lstrip()\n",
    "\n",
    "            # Remove trailing email\n",
    "            if \"@\" in name.split(\",\")[-1]:\n",
    "                name = name.rsplit(\" \", 1)[0].strip().strip(\":\")\n",
    "                name = name.rstrip(\":\").rstrip()\n",
    "                name = name.removesuffix(\"Electronic address\").rstrip()\n",
    "                name = name.rstrip(\".\").rstrip()\n",
    "\n",
    "            counter[name] += 1"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2a262b29-5c9e-4583-b0e7-9d76a9d271c0",
   "metadata": {},
   "source": [
    "Next steps:\n",
    "\n",
    "1. Identify country of affiliation\n",
    "2. Use country to filter our ROR groundings based on correct country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2665643-21fa-4d41-8633-df678f6d9e11",
   "metadata": {},
   "source": [
    "def _get_country(parts):\n",
    "    last = parts[-1]\n",
    "    sm = geonames_grounder.ground(last)\n",
    "    if not sm:\n",
    "        return None, None\n",
    "    if len(sm) == 1:\n",
    "        return sm[0].term.id, sm[0].term.entry_name\n",
    "    # This happens for Mexico and Singapore since they have a city the same name as the country\n",
    "    # in many places, there is no country written. This almost 100% USA, which sometimes just writes states\n",
    "    # print(\"got multiple for\", last)\n",
    "    # print(sm)\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def _get_country_for_ror(ror_id):\n",
    "    \"\"\"Return the geonames id for the ROR's country.\"\"\"\n",
    "    rv = ror_to_country_geoname[ror_id]\n",
    "    if isinstance(rv, list):\n",
    "        return rv[0]\n",
    "    return rv\n",
    "\n",
    "\n",
    "def _get_country_for_geonames(geonames_id):\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def _get_institution(parts: str, country_id: str | None, country_name):\n",
    "    # don't need to look at the last bit again if country is given\n",
    "    rparts = parts[:-1] if country_id else parts\n",
    "    for part in reversed(rparts):\n",
    "        if part.isdigit():  # zip code\n",
    "            continue\n",
    "        if len(part) < 3:\n",
    "            continue  # probably a state\n",
    "        if \" \" in part and part.split()[-1].isdigit():  # something plus space plus zip code\n",
    "            continue\n",
    "        if geonames_grounder.ground(part):  # it's a city/state/country\n",
    "            continue\n",
    "\n",
    "        matches = organization_grounder.ground(part)\n",
    "        if not matches and part.endswith(\")\"):\n",
    "            # Try stripping off some acronym in parentheses\n",
    "            part = part.rsplit(\"(\", 1)[0]\n",
    "            matches = organization_grounder.ground(part)\n",
    "        if not matches and part.startswith(\"The \"):\n",
    "            part = part.removeprefix(\"The\").strip()\n",
    "            matches = organization_grounder.ground(part)\n",
    "        for suffix in [\"School of Medicine\", \"College of Medicine\", \"Faculty of Medicine\"]:\n",
    "            if not matches and part.endswith(suffix):\n",
    "                part = part.removeprefix(suffix).strip()\n",
    "                matches = organization_grounder.ground(part)\n",
    "        if not matches:\n",
    "            continue\n",
    "        if len(matches) == 1:\n",
    "            return matches[0].term.id, matches[0].term.entry_name\n",
    "\n",
    "        # Do some disambiguating\n",
    "        if country_id is None:\n",
    "            print(f\"Got multiple matches but didn't have a country to disambiguate on: {part}\")\n",
    "            for m in matches:\n",
    "                print(\"  https://ror.org/\" + m.term.id, m.term.entry_name)\n",
    "            print()\n",
    "            continue\n",
    "\n",
    "        for match in matches:\n",
    "            match_country_geonames = _get_country_for_ror(match.term.id)\n",
    "            if match_country_geonames == country_id:\n",
    "                return match.term.id, match.term.entry_name\n",
    "\n",
    "        print(\n",
    "            f\"\\nfrom {parts}\\n could not disambiguate '{part}' based on country '{country_name}':\"\n",
    "        )\n",
    "        for m in matches:\n",
    "            print(\"    https://ror.org/\" + m.term.id, m.term.entry_name)\n",
    "        print()\n",
    "\n",
    "    print(f\"\\nfailed: {parts}\", f\"(country = {country_name})\" if country_name else \"\")\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "passed = 0\n",
    "failed = defaultdict(list)\n",
    "for text, count in sorted(counter.items()):\n",
    "    parts = [part.strip() for part in text.split(\",\")]\n",
    "    while any(\n",
    "        parts[0].startswith(part_prefix)\n",
    "        for part_prefix in (\"Division\", \"Department\", \"Faculty of\", \"Laboratory of\", \"Office of\")\n",
    "    ):\n",
    "        parts = parts[1:]  # chomp away many\n",
    "    country_geonames_id, country_name = _get_country(parts)\n",
    "    i = _get_institution(parts, country_geonames_id, country_name)\n",
    "    if i:\n",
    "        passed += 1\n",
    "    else:\n",
    "        failed[country_name].append(text)\n",
    "\n",
    "print(passed, sum(map(len, failed.values())))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95da7781-f7b1-4c5f-b1cc-686058861d60",
   "metadata": {},
   "source": [
    "Counter({country_name: len(strings) for country_name, strings in failed.items()})"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8bed86d-9a9f-4598-8c54-ffe9fc809494",
   "metadata": {},
   "source": [
    "failed[None]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567182d8-954f-487a-afcd-fbe55edbf460",
   "metadata": {},
   "source": [
    "with open(\"affiliations.tsv\", \"w\") as file:\n",
    "    for name, count in sorted(counter.items()):\n",
    "        matches = annotate(name, grounder=grounder)\n",
    "        print(matches)\n",
    "        break\n",
    "\n",
    "        print(name, count, sep=\"\\t\", file=file)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
